# ğŸ­ Audio Emotion Recognition System - Clean Version

A comprehensive deep learning system for recognizing emotions from speech audio using multiple neural network architectures and pre-trained models.

## ğŸ† Performance Results

### Top Performing Models

| Rank | Model | Type | Test Accuracy | Validation Accuracy | Parameters | Training Time |
|------|-------|------|---------------|-------------------|------------|---------------|
| ğŸ¥‡ | **ResNet** | Custom Deep Learning | **76.34%** | **67.04%** | 191,416 | ~45 min |
| ğŸ¥ˆ | SimpleCNN | Custom Deep Learning | 68.72% | 65.41% | 191,416 | ~40 min |
| ğŸ¥‰ | SimpleCNNAudio | Pre-trained Fine-tuned | 60.62% | 58.48% | 4,456,648 | ~30 min |
| 4 | FixedWav2Vec2 | Pre-trained Fine-tuned | 58.90% | 61.22% | ~95M | ~40 min |
| 5 | Transformer | Custom Deep Learning | 15.92% | 16.87% | 298,568 | ~35 min |
| 6 | LSTM | Custom Deep Learning | 15.07% | 16.95% | 191,176 | ~25 min |

**Champion**: Custom ResNet achieved **76.34% test accuracy** (511% improvement over random baseline of 12.5%)

## ğŸ“Š Dataset Information

### Combined Dataset Statistics

| Dataset | Files | Emotions | Source |
|---------|-------|----------|--------|
| **RAVDESS** | 1,440 | 8 emotions | [Zenodo](https://zenodo.org/record/1188976) |
| **CREMA-D** | 7,442 | 6 emotions | [GitHub](https://github.com/CheyneyComputerScience/CREMA-D) |
| **TESS** | 2,800 | 7 emotions | [Kaggle](https://www.kaggle.com/ejlok1/toronto-emotional-speech-set-tess) |
| **Total** | **11,682** | **8 emotions** | Combined |

### Emotion Distribution

| Emotion | Files | Percentage |
|---------|-------|------------|
| Angry | 1,863 | 15.9% |
| Disgust | 1,863 | 15.9% |
| Fearful | 1,863 | 15.9% |
| Happy | 1,863 | 15.9% |
| Sad | 1,863 | 15.9% |
| Neutral | 1,583 | 13.6% |
| Surprised | 592 | 5.1% |
| Calm | 192 | 1.6% |

## ğŸ—ï¸ Clean Project Structure

```
CLEAN_PROJECT/
â”œâ”€â”€ ğŸ“ src/                          # Source code modules
â”‚   â”œâ”€â”€ ğŸ“ models/                   # Model architectures
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ custom_models.py         # Transformer, LSTM, ResNet, DenseNet
â”‚   â”‚   â”œâ”€â”€ pretrained_models.py     # Wav2Vec2, CNN models
â”‚   â”‚   â””â”€â”€ ensemble_model.py        # Ensemble models
â”‚   â”œâ”€â”€ ğŸ“ data/                     # Data handling
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py              # Dataset classes
â”‚   â”‚   â”œâ”€â”€ preprocessing.py        # Audio preprocessing
â”‚   â”‚   â””â”€â”€ utils.py                # Data utilities
â”‚   â”œâ”€â”€ ğŸ“ training/                # Training components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py              # Training classes
â”‚   â”‚   â””â”€â”€ densenet_trainer.py     # DenseNet specific trainer
â”‚   â”œâ”€â”€ ğŸ“ evaluation/              # Evaluation and metrics
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py              # Evaluation metrics
â”‚   â”‚   â””â”€â”€ comparison.py           # Model comparison
â”‚   â””â”€â”€ ğŸ“ utils/                   # General utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py               # Configuration management
â”‚       â””â”€â”€ logger.py               # Logging utilities
â”œâ”€â”€ ğŸ“ scripts/                     # Execution scripts
â”‚   â”œâ”€â”€ train_all_models.py        # Train all models
â”‚   â”œâ”€â”€ compare_models.py          # Compare performance
â”‚   â”œâ”€â”€ predict_emotion.py         # Make predictions
â”‚   â”œâ”€â”€ train_densenet_full_dataset.py  # DenseNet training
â”‚   â”œâ”€â”€ train_optimized_densenet.py     # Optimized DenseNet training
â”‚   â”œâ”€â”€ test_epoch_52_best_model.py     # Test best DenseNet
â”‚   â”œâ”€â”€ test_ensemble_fixed.py          # Test ensemble model
â”‚   â””â”€â”€ test_ensemble.py               # Basic ensemble test
â”œâ”€â”€ ğŸ“ models/                      # Saved model checkpoints
â”‚   â”œâ”€â”€ ğŸ“ densenet/               # DenseNet models
â”‚   â”‚   â”œâ”€â”€ densenet_current_best.pth
â”‚   â”‚   â”œâ”€â”€ densenet_epoch_52_best.pth
â”‚   â”‚   â””â”€â”€ densenet_epoch_54_backup.pth
â”‚   â”œâ”€â”€ ğŸ“ resnet/                 # ResNet models
â”‚   â”‚   â””â”€â”€ best_ResNet.pth
â”‚   â”œâ”€â”€ ğŸ“ simplecnn/              # SimpleCNN models
â”‚   â”‚   â””â”€â”€ best_SimpleCNN.pth
â”‚   â”œâ”€â”€ ğŸ“ lstm/                   # LSTM models
â”‚   â”‚   â””â”€â”€ best_LSTM.pth
â”‚   â”œâ”€â”€ ğŸ“ transformer/            # Transformer models
â”‚   â”‚   â””â”€â”€ best_Transformer.pth
â”‚   â””â”€â”€ ğŸ“ pretrained/             # Pre-trained models
â”‚       â”œâ”€â”€ ğŸ“ simplecnnaudio/
â”‚       â””â”€â”€ ğŸ“ wav2vec2/
â”œâ”€â”€ ğŸ“ results/                     # Training results & reports
â”‚   â”œâ”€â”€ ğŸ“ densenet/               # DenseNet results
â”‚   â”œâ”€â”€ ğŸ“ ensemble/               # Ensemble results
â”‚   â””â”€â”€ ğŸ“ comparison/             # Model comparison results
â”œâ”€â”€ ğŸ“ data/                        # Dataset
â”‚   â””â”€â”€ ğŸ“ organized_by_emotion/   # Processed dataset (8 emotion folders)
â”œâ”€â”€ ğŸ“ docs/                        # Documentation
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“„ paths.json                   # Configuration paths
â””â”€â”€ ğŸ“„ README_CLEAN.md             # This file
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Train All Models
```bash
python scripts/train_all_models.py
```

### 3. Compare Model Performance
```bash
python scripts/compare_models.py
```

### 4. Make Predictions
```bash
python scripts/predict_emotion.py --model models/resnet/best_ResNet.pth --audio audio.wav
```

## ğŸ§  Model Details

### Custom Deep Learning Models
- **ResNet**: Residual neural network with skip connections
- **SimpleCNN**: Basic convolutional neural network
- **Transformer**: Self-attention based architecture
- **LSTM**: Long short-term memory network
- **DenseNet**: Densely connected convolutional network

### Pre-trained Fine-tuned Models
- **Wav2Vec2**: Pre-trained speech representation model
- **SimpleCNNAudio**: Audio-specific CNN architecture

## ğŸ“Š Results and Analysis

### Model Performance Summary
- **Best Overall**: ResNet (76.34% test accuracy)
- **Most Efficient**: SimpleCNN (68.72% accuracy, fast training)
- **Best Pre-trained**: SimpleCNNAudio (60.62% accuracy)

### Key Findings
1. **Custom models outperform pre-trained models** for this specific emotion recognition task
2. **ResNet architecture** provides the best balance of accuracy and efficiency
3. **Transformer and LSTM** showed poor performance, likely due to insufficient data or architecture mismatch
4. **Class imbalance** affects model performance, especially for underrepresented emotions

## ğŸ”§ Development

### Adding New Models
1. Define model in `src/models/custom_models.py`
2. Add training logic in `src/training/trainer.py`
3. Register in `scripts/train_all_models.py`

### Modifying Data Processing
1. Update `src/data/preprocessing.py`
2. Test with `src/data/utils.py`
3. Retrain models to see impact

## ğŸ“ Notes

This clean version consolidates all the best components from the original project:
- âœ… Removed duplicate files and scripts
- âœ… Organized models by type
- âœ… Consolidated results directories
- âœ… Maintained all working functionality
- âœ… Preserved all trained models and results
- âœ… Clean, maintainable structure

## ğŸ¯ Next Steps

1. **Hyperparameter Optimization**: Fine-tune ResNet for even better performance
2. **Data Augmentation**: Implement audio augmentation techniques
3. **Ensemble Methods**: Combine best models for improved accuracy
4. **Real-time Inference**: Optimize models for real-time emotion recognition
5. **Mobile Deployment**: Convert models for mobile applications

---

**Last Updated**: September 7, 2025  
**Version**: Clean v1.0  
**Status**: Production Ready âœ…
