# ğŸ§­ Project Navigation Guide

This guide helps you navigate the Audio Emotion Recognition System codebase efficiently.

## ğŸ“ Repository Structure Overview

```
Digital_Health_project/
â”œâ”€â”€ ğŸ“„ README.md                    # Main project documentation
â”œâ”€â”€ ğŸ“„ CONTRIBUTING.md              # Contribution guidelines
â”œâ”€â”€ ğŸ“„ NAVIGATION.md                # This navigation guide
â”œâ”€â”€ ğŸ“„ CITATION.cff                 # Academic citation format
â”œâ”€â”€ ğŸ“„ LICENSE                      # MIT license and dataset attributions
â”œâ”€â”€ ğŸ“„ .gitignore                   # Git ignore patterns
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“ src/                         # ğŸ¯ Main source code (ORGANIZED STRUCTURE)
â”œâ”€â”€ ğŸ“ scripts/                     # ğŸ¯ Execution scripts (START HERE)
â”œâ”€â”€ ğŸ“ Project/                     # ğŸ›ï¸ Legacy code (REFERENCE ONLY)
â”œâ”€â”€ ğŸ“ models/                      # ğŸ’¾ Saved model checkpoints
â”œâ”€â”€ ğŸ“ results/                     # ğŸ“Š Training results and reports
â”œâ”€â”€ ğŸ“ logs/                        # ğŸ“ Training logs
â””â”€â”€ ğŸ“ organized_by_emotion/        # ğŸµ Dataset (if available)
```

## ğŸ¯ Quick Start Paths

### ğŸ”¥ I want to run the system immediately
1. **Start here**: `scripts/train_all_models.py` - Train all models
2. **Then run**: `scripts/compare_models.py` - Compare performance
3. **Finally**: `scripts/predict_emotion.py` - Make predictions

### ğŸ§  I want to understand the models
1. **Custom models**: `src/models/custom_models.py`
2. **Pre-trained models**: `src/models/pretrained_models.py`
3. **Training logic**: `src/training/trainer.py`

### ğŸ“Š I want to see results and analysis
1. **Latest results**: `results/comprehensive_comparison_report.md`
2. **Model comparison**: `results/model_comparison.png`
3. **Detailed metrics**: `results/comparisons/`

### ğŸ”§ I want to modify the system
1. **Configuration**: `src/utils/config.py`
2. **Data processing**: `src/data/preprocessing.py`
3. **Training setup**: `src/training/trainer.py`

## ğŸ“ Key File Locations

### ğŸš€ Execution Scripts (scripts/)

| Script | Purpose | Usage |
|--------|---------|-------|
| `train_all_models.py` | Train all models | `python scripts/train_all_models.py` |
| `compare_models.py` | Compare model performance | `python scripts/compare_models.py` |
| `predict_emotion.py` | Make predictions | `python scripts/predict_emotion.py --help` |

### ğŸ§© Source Code (src/)

#### Models (src/models/)
- `custom_models.py` - ResNet, Transformer, LSTM architectures
- `pretrained_models.py` - Wav2Vec2, SimpleCNNAudio models
- `__init__.py` - Model registry and imports

#### Data (src/data/)
- `dataset.py` - EmotionDataset class for PyTorch
- `preprocessing.py` - Audio feature extraction
- `utils.py` - Data loading and splitting utilities
- `__init__.py` - Data module exports

#### Training (src/training/)
- `trainer.py` - CustomModelTrainer and base training logic
- `__init__.py` - Training module exports

#### Evaluation (src/evaluation/)
- `metrics.py` - Evaluation metrics and scoring
- `comparison.py` - Model comparison utilities
- `__init__.py` - Evaluation module exports

#### Utils (src/utils/)
- `config.py` - Configuration management
- `logger.py` - Logging utilities
- `__init__.py` - Utils module exports

### ğŸ›ï¸ Legacy Code (Project/)

**Note**: This directory contains the original development code. Use for reference only.

| File | Purpose | Status |
|------|---------|--------|
| `emotion_recognition_models.py` | Original ML models | âœ… Reference |
| `data_preprocessing.py` | Original preprocessing | âœ… Reference |
| `train_models.py` | Original training script | âœ… Reference |
| `archive/` | Old experimental code | ğŸ—„ï¸ Archived |

## ğŸ¯ Common Use Cases

### 1. Training a New Model

```bash
# Option A: Train all models
python scripts/train_all_models.py

# Option B: Train specific model type (edit script first)
python scripts/training/train_custom_models.py
```

**Files to modify**:
- `src/models/custom_models.py` - Add new model class
- `src/training/trainer.py` - Add training logic if needed
- `scripts/train_all_models.py` - Register new model

### 2. Adding New Features

**Audio Features**:
- Modify: `src/data/preprocessing.py`
- Function: `extract_features()`

**Model Architecture**:
- Add to: `src/models/custom_models.py`
- Inherit from: `torch.nn.Module`

**Training Process**:
- Extend: `src/training/trainer.py`
- Override: `train()` method

### 3. Analyzing Results

**Performance Comparison**:
```bash
python scripts/compare_models.py
```

**Detailed Analysis**:
- Check: `results/comprehensive_comparison_report.md`
- Visualizations: `results/visualizations/`

**Individual Model Results**:
- ResNet: `results/resnet/`
- LSTM: `results/lstm/`
- Transformer: `results/transformer/`

### 4. Making Predictions

**Single File**:
```bash
python scripts/predict_emotion.py \
  --model models/resnet/best_ResNet.pth \
  --audio audio.wav
```

**Batch Processing**:
```bash
python scripts/predict_emotion.py \
  --model models/resnet/best_ResNet.pth \
  --audio_dir audio_folder/ \
  --output predictions.json
```

## ğŸ” Finding Specific Components

### ğŸµ Audio Processing
- **Loading**: `src/data/preprocessing.py::load_audio()`
- **Features**: `src/data/preprocessing.py::extract_features()`
- **Normalization**: `src/data/preprocessing.py::normalize_audio()`

### ğŸ§  Model Definitions
- **ResNet**: `src/models/custom_models.py::EmotionResNet`
- **Transformer**: `src/models/custom_models.py::EmotionTransformer`
- **LSTM**: `src/models/custom_models.py::EmotionLSTM`
- **Wav2Vec2**: `src/models/pretrained_models.py::FixedWav2Vec2`

### ğŸ¯ Training Components
- **Main Trainer**: `src/training/trainer.py::CustomModelTrainer`
- **Training Loop**: `src/training/trainer.py::train()`
- **Validation**: `src/training/trainer.py::validate()`

### ğŸ“Š Evaluation & Metrics
- **Accuracy**: `src/evaluation/metrics.py::calculate_accuracy()`
- **Classification Report**: `src/evaluation/metrics.py::classification_report()`
- **Confusion Matrix**: `src/evaluation/metrics.py::confusion_matrix()`

## ğŸ› ï¸ Development Workflows

### Adding a New Model

1. **Define Model** (`src/models/custom_models.py`):
   ```python
   class NewModel(nn.Module):
       def __init__(self, num_classes=8):
           # Implementation
   ```

2. **Register Model** (`src/models/__init__.py`):
   ```python
   from .custom_models import NewModel
   ```

3. **Add Training** (`scripts/train_all_models.py`):
   ```python
   models_to_train = ['resnet', 'lstm', 'transformer', 'newmodel']
   ```

4. **Test Model**:
   ```bash
   python scripts/train_all_models.py
   ```

### Modifying Data Processing

1. **Update Preprocessing** (`src/data/preprocessing.py`)
2. **Test Changes**:
   ```python
   from src.data.preprocessing import extract_features
   features = extract_features("test_audio.wav")
   ```

3. **Retrain Models**:
   ```bash
   python scripts/train_all_models.py
   ```

### Debugging Training Issues

1. **Check Logs**: `logs/emotion_recognition_*.log`
2. **Validate Data**: `src/data/utils.py::validate_dataset()`
3. **Test Individual Components**:
   ```python
   from src.models.custom_models import EmotionResNet
   model = EmotionResNet()
   print(model)
   ```

## ğŸ“Š Understanding Results

### Model Performance Files

| File Pattern | Content |
|--------------|---------|
| `results/*/best_*.pth` | Trained model checkpoints |
| `results/*/test_results.pkl` | Detailed test results |
| `results/*/classification_report.pkl` | Sklearn classification report |
| `results/*/test_metrics.csv` | CSV format metrics |

### Comparison Reports

| File | Content |
|------|---------|
| `results/comprehensive_comparison_report.md` | Complete analysis |
| `results/model_comparison.png` | Performance visualization |
| `results/overall_comparison.csv` | Tabular comparison |

## ğŸ¯ Performance Optimization

### GPU Utilization
- **Check**: `src/training/trainer.py::__init__()` - Device selection
- **Monitor**: Use `nvidia-smi` during training

### Memory Optimization
- **Batch Size**: `src/utils/config.py` - Reduce if OOM errors
- **Model Size**: `src/models/` - Check parameter counts

### Training Speed
- **Data Loading**: `src/data/dataset.py` - Parallel data loading
- **Mixed Precision**: `src/training/trainer.py` - Enable AMP

## ğŸ”§ Configuration Guide

### Key Configuration Files

| File | Purpose |
|------|---------|
| `src/utils/config.py` | Main configuration |
| `requirements.txt` | Dependencies |
| `.gitignore` | Git exclusions |

### Common Configuration Changes

**Audio Settings**:
```python
# src/utils/config.py
AUDIO_CONFIG = {
    'sample_rate': 16000,  # Change sample rate
    'duration': 3.0,       # Change clip duration
    'n_mels': 64,          # Change mel bands
}
```

**Training Settings**:
```python
# src/utils/config.py
TRAINING_CONFIG = {
    'batch_size': 16,      # Adjust for memory
    'learning_rate': 0.001, # Tune learning rate
    'epochs': 30,          # Change training duration
}
```

## ğŸ¯ Troubleshooting

### Common Issues

| Issue | Location | Solution |
|-------|----------|----------|
| CUDA out of memory | `src/utils/config.py` | Reduce batch_size |
| Audio file errors | `src/data/preprocessing.py` | Check file formats |
| Model not converging | `src/training/trainer.py` | Adjust learning rate |
| Import errors | `requirements.txt` | Update dependencies |

### Debug Commands

```bash
# Check data
python -c "from src.data.utils import validate_dataset; validate_dataset()"

# Test model
python -c "from src.models.custom_models import EmotionResNet; print(EmotionResNet())"

# Verify GPU
python -c "import torch; print(torch.cuda.is_available())"
```

## ğŸ“ Getting Help

1. **Documentation**: Start with `README.md`
2. **Issues**: Check existing GitHub issues
3. **Code Examples**: Look in `scripts/` directory
4. **Configuration**: Check `src/utils/config.py`

---

**Quick Reference Card**:
- ğŸš€ **Run Everything**: `python scripts/train_all_models.py`
- ğŸ” **Compare Models**: `python scripts/compare_models.py`
- ğŸ¯ **Make Prediction**: `python scripts/predict_emotion.py --help`
- ğŸ§  **View Models**: `src/models/`
- ğŸ“Š **Check Results**: `results/comprehensive_comparison_report.md`

Happy coding! ğŸ‰
